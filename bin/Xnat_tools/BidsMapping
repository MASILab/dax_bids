#!/usr/bin/env python

'''
Create/Upload BIDS datatype/tasktype mapping.

Created on October, 2019

@author: Praitayini Kanakaraj, Electrical Engineering, Vanderbilt University
'''
import os
import re
import csv
import sys
import json
import logging
import argparse
from dax import XnatUtils
from datetime import datetime

UNSPECIFIED = object()
def add_parser_args():
    """
    The arguments for the tool
    :return:
    """
    argp = argparse.ArgumentParser()
    argp.add_argument('--host', dest='host', default=None,
                      help='Host for XNAT. Default: using $XNAT_HOST.')
    argp.add_argument('-u', '--username', dest='username', default=None,
                      help='Username for XNAT. Default: using $XNAT_USER.')
    argp.add_argument("-o", "--logfile", dest="logfile", default=None,
                      help="Write the display/output in a file given to this OPTIONS.")
    argp.add_argument('--project', dest="project", default=None,
                      help='Project to create/update BIDS mapping file')
    argp.add_argument('--type', dest="type", default=None,
                      help='The type of mapping either datatype or tasktype')
    argp.add_argument('--create', dest="create", action=None, default=UNSPECIFIED, nargs='?',
                      help='Create the given BIDS new mapping file at project level. (EG. --create <mappingfile>.csv)'
                           'Default create creates the default mapping at project file. (EG. --create)'
                           'csvfile EG: '
                           'series_description,datatype'
                           'T1W/3D/TFE,anat'
                           'Resting State,func')
    argp.add_argument('--update', dest="update", default=None,
                      help='Update the existing BIDS mapping file at project level. (EG. --update <mappingfile>.csv)'
                           'This option can only add rules')
    argp.add_argument('--replace', dest="replace",  default=None,
                      help='Replace the existing BIDS mapping file at project level. (EG. --replace <mappingfile>.csv)'
                           'This option can remove and add new rules')
    argp.add_argument('--revert', dest="revert", default=None,
                      help='Revert to an old mapping from a specific date/time. (EG: --revert 10-17-19-21:32:15'
                           'or --revert 10-17-19). Check the LOGFILE at project level for the date')
    argp.add_argument('--download', dest="download",  action=None,
                      help='Downloads the current BIDS mapping file')
    argp.add_argument('--template', dest="template",  default=None,
                      help='Default mapping template')

    return argp

def setup_info_logger(name, logfile):
    """
    Using logger for the executables output.
     Setting the information for the logger.

    :param name: Name of the logger
    :param logfile: log file path to write outputs
    :return: logging object
    """
    if logfile:
        handler = logging.FileHandler(logfile, 'w')
    else:
        handler = logging.StreamHandler()

    logger = logging.getLogger(name)
    logger.setLevel(logging.INFO)
    logger.addHandler(handler)
    return logger

def template():
    """
    Function to generate the series description from a project
    in csv
    :return:
    """
    #TODO sd | default mapping | rule at project level
    sd_dict = []
    template_dir = OPTIONS.template
    scans_list_global = XNAT.get_project_scans(project)
    for sd in scans_list_global:
        sd_dict.append(sd['series_description'])
    with open(template_dir, "w+") as f:
        json.dump(sd_dict, f, indent=2)

def default():
    """
    Function to make the default mapping at project level if
    mapping does not exit
    #TODO go back to default when wanted? use findchange for logging??
    :return:
    """
    new_mapping = dict()
    new_mapping['LANDMAN'] = {}

    if mapping_type == 'datatype':
        scans_list_global = XNAT.get_project_scans('LANDMAN')

        for sd in scans_list_global:
            c = re.search('T1|T2|T1W', sd['series_description'])
            if not c == None:
                sd_anat = sd['series_description']
                new_mapping['LANDMAN'][sd_anat] = "anat"

        for sd in scans_list_global:
            c = re.search('rest|Resting state', sd['series_description'], flags=re.IGNORECASE)
            if not c == None:
                sd_func = sd['series_description']
                new_mapping['LANDMAN'][sd_func] = "func"

        for sd in scans_list_global:
            c = re.search('dwi|dti', sd['series_description'], flags=re.IGNORECASE)
            if not c == None:
                sd_dwi = sd['series_description']
                new_mapping['LANDMAN'][sd_dwi] = "dwi"

        for sd in scans_list_global:
            c = re.search('Field|B0', sd['series_description'], flags=re.IGNORECASE)
            if not c == None:
                sd_fmap = sd['series_description']
                new_mapping['LANDMAN'][sd_fmap] = "fmap"

    if mapping_type == 'tasktype':
        scans_list_global = XNAT.get_project_scans('LANDMAN')
        for sd in scans_list_global:
            c = re.search('rest', sd['series_description'], flags=re.IGNORECASE)
            if not c == None:
                sd_func = sd['series_description']
                new_mapping['LANDMAN'][sd_func] = "rest"

    new_json_name = d_m_y + '_' + mapping_type + '.json'
    is_json_present = False
    for res in XNAT.select(res_files).get():
        if not res.endswith('.json'):
            continue
        else:
            is_json_present = True

    if not is_json_present:
        XNAT.select(os.path.join(res_files, new_json_name)).put(src=json.dumps(new_mapping, indent=2))
        log_new_mapping(new_mapping)
        LOGGER.info('CREATED: Default mapping file %s is uploaded' % new_json_name)
    else:
        LOGGER.info('Datatype mapping exists at project level. You can update it using --update to update it \
    or --replace to replace the mapping')


def create():
    """
    Function to read the given csv file and create new mapping
    at project level
    :return:
    """
    dir_new_csv = OPTIONS.create
    new_mapping = dict()
    new_mapping[project] = {}
    with open(dir_new_csv) as csvFile:
        csvReader = csv.DictReader(csvFile)
        for rows in csvReader:
            sd = rows['series_description']
            if mapping_type == 'datatype':
                new_mapping[project][sd] = rows['datatype']
            else:
                new_mapping[project][sd] = rows['tasktype']
    LOGGER.info('date %s' % (date.strftime("%d-%m-%y-%H:%M:%S")))
    new_json_name = d_m_y + '_' + mapping_type + '.json'
    is_json_present = False
    for res in XNAT.select(res_files).get():
        if not res.endswith('.json'):
            continue
        else:
            is_json_present = True

    if not is_json_present:
        XNAT.select(os.path.join(res_files, new_json_name)).put(src=json.dumps(new_mapping, indent=2))
        log_new_mapping(new_mapping)
        LOGGER.info('CREATED: New mapping file %s is uploaded' % new_json_name)
    else:
        LOGGER.info('Datatype mapping exists at project level. You can update it using --update to update it \
    or --replace to replace the mapping')


def log_new_mapping(d):
    """
    Logging when new mapping is created fat project level
    :param d: new mapping
    :return:
    """
    for k, v in d[project].iteritems():
        row0 = d_m_y, " + ", k + " : " + v
        CSVWRITER.writerow(row0)


def update():
    """
    Function to read the csv file with new rules and to add new rules
    at project level
    :return:
    """
    new_json_name = d_m_y + '_' + mapping_type + '.json'
    if OPTIONS.update:
        src_path = OPTIONS.update
    if OPTIONS.replace:
        src_path = OPTIONS.replace
    new_mapping = dict()
    new_mapping['LANDMAN'] = {}
    with open(src_path, 'r') as csvFile:
        csvReader = csv.DictReader(csvFile)
        for rows in csvReader:
            sd = rows['sd']
            new_mapping['LANDMAN'][sd] = rows['dt']

    for res in XNAT.select(res_files).get():
        if res.endswith('.json'):
            with open(XNAT.select(os.path.join(res_files, res)).get(), "r+") as f:
                prev_mapping = json.load(f)
                if project in prev_mapping.keys():
                    for k, v in new_mapping.items():
                        if OPTIONS.update:
                            findDiff(new_mapping, prev_mapping)
                            prev_mapping[k].update(v)
                        if OPTIONS.replace:
                            findDiff_change(new_mapping, prev_mapping)
                            prev_mapping = new_mapping

                    XNAT.select(os.path.join(res_files, new_json_name)).put(src=
                                                                            json.dumps(prev_mapping, indent=2),
                                                                            overwrite=True)
                    XNAT.select(os.path.join(res_files, res)).delete()
                    LOGGER.info('UPDATED: uploaded mapping file %s' % new_json_name)
                else:
                    LOGGER.error('ERROR: The mapping file format should have project as key')


def revert():
    """
    Function to go back a mapping of a previous date/time
    using the log file at project level
    :return:
    """
    new_json_name = d_m_y + '_' + mapping_type + '.json'
    orig_mapping = None
    for res in XNAT.select(res_files).get():
        if res.endswith('.json'):
            res_obj = XNAT.select(os.path.join(res_files, res))
            with open(res_obj.get(), "r+") as f:
                prev_mapping = json.load(f)
                f.seek(0, 0)
                orig_mapping = json.load(f)

                with open(XNAT.select(os.path.join(res_files, 'LOGFILE.txt')).get(), "r+") as lf:
                    lines = lf.readlines()
                    lines.reverse()
                    for l in lines:
                        if not l.startswith(OPTIONS.revert):
                            mapping_all = l.split(",")
                            if mapping_all[1].strip() == '+':
                                prev_mapping[project].pop(mapping_all[2].split(':')[0].strip())
                            if mapping_all[1].strip() == '-':
                                prev_mapping[project].update({mapping_all[2].split(':')[0].
                                                             strip(): mapping_all[2].split(':')[1].strip()})
                        else:
                            break
                findDiff_change(prev_mapping, orig_mapping)
            XNAT.select(os.path.join(res_files, new_json_name)).put(src=json.dumps(prev_mapping, indent=2))
            res_obj.delete()


def findDiff(d1, d2, path=""):
    """
    Function to record/log the changing made when adding rules
    :param d1: dict with new mapping
    :param d2: dict with old mapping
    :param path: ""
    :return:
    """
    for k, v in d1.iteritems():
        if k not in d2.keys():
            row1 = d_m_y, " + ", k + " : " + v
            CSVWRITER.writerow(row1)
        else:
            if type(d1[k]) is dict:
                if path == "":
                    path = k
                else:
                    path = path + "->" + k
                findDiff(d1[k], d2[k], path)
            else:
                if d1[k] != d2[k]:
                    row2 = d_m_y, " - ", k + " : " + d2[k]
                    CSVWRITER.writerow(row2)
                    row3 = d_m_y, " + ", k + " : " + d1[k]
                    CSVWRITER.writerow(row3)


def findDiff_change(d1, d2, path=""):
    """
    Function to record/log the changing made when reverting rules
    :param d1: dict with new mapping
    :param d2: dict with previous mapping
    :param path: ""
    :return:
    """
    for k, v in d1.iteritems():
        if k not in d2.keys():
            row4 = d_m_y, " + ", k + " : " + v
            CSVWRITER.writerow(row4)
    for k, v in d2.iteritems():
        if k not in d1.keys():
            row5 = d_m_y, " - ", k + " : " + v
            CSVWRITER.writerow(row5)
        else:
            if type(d1[k]) is dict:
                if path == "":
                    path = k
                else:
                    path = path + "->" + k
                findDiff_change(d1[k], d2[k], path)



def mapping_download():
    """
    Function to download the mapping file at project level
    :return:
    """
    download_file = OPTIONS.download
    XNAT.select('/projects/' + project + '/resources/BIDS_' + mapping_type + '/files/' + download_file).get(
                 dest=os.path.join(os.getcwd(), download_file))
    LOGGER.info('DOWNLOADED: File %s at %s' % (download_file, os.getcwd()))


if __name__ == '__main__':
    parser = add_parser_args()
    OPTIONS = parser.parse_args()
    if OPTIONS.host:
        HOST = OPTIONS.host
    else:
        HOST = os.environ['XNAT_HOST']
    if OPTIONS.username:
        MSG = "Please provide the password for user <%s> on xnat(%s):"
        PWD = getpass.getpass(prompt=MSG % (OPTIONS.username, HOST))
    else:
        PWD = None
    LOGGER = setup_info_logger('BidsMapping', OPTIONS.logfile)
    MSG = 'INFO: connection to xnat <%s>:' % (HOST)
    LOGGER.info(MSG)
    XNAT = XnatUtils.get_interface(host=OPTIONS.host,
                                 user=OPTIONS.username,
                                 pwd=PWD)
    date = datetime.now()
    d_m_y = date.strftime("%m-%d-%y-%H:%M:%S")

    if not OPTIONS.project:
        LOGGER.info("WARNING: Project is require. Use --project")
    else:
        project = OPTIONS.project
        if OPTIONS.template:
            template()
        else:
            if not OPTIONS.type:
                LOGGER.info("WARNING: Type is required. Use --type")
            else:
                mapping_type = OPTIONS.type
                CSVWRITER = None
                res_files = '/data/projects/' + project + '/resources/BIDS_' + mapping_type + '/files'

                xnat_logfile = XNAT.select(os.path.join(res_files, 'LOGFILE.txt'))
                if not xnat_logfile.exists():
                    if OPTIONS.revert:
                        LOGGER.error('Cannot perform --revert. Create mapping with --create option first')
                        sys.exit()
                    xnat_logfile.put(src="Logfile\n")
                LOGFILE = xnat_logfile.get()
                csvfilewrite = open(LOGFILE, 'ab')
                CSVWRITER = csv.writer(csvfilewrite, delimiter=',')
                if OPTIONS.create:
                    create()
                if OPTIONS.create == None:
                    default()
                if OPTIONS.update or OPTIONS.replace:
                    update()
                if OPTIONS.revert:
                    revert()
                if OPTIONS.download:
                    mapping_download()

                csvfilewrite.close()
                XNAT.select(os.path.join(res_files, 'LOGFILE.txt')).put(src=LOGFILE, overwrite=True)











